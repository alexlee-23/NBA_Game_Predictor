{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season_id', 'team_id_home', 'team_abbreviation_home', 'team_name_home',\n",
      "       'game_id', 'game_date', 'matchup_home', 'wl_home', 'min', 'fgm_home',\n",
      "       'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home',\n",
      "       'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home', 'dreb_home',\n",
      "       'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pf_home',\n",
      "       'pts_home', 'plus_minus_home', 'video_available_home', 'team_id_away',\n",
      "       'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away',\n",
      "       'fgm_away', 'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away',\n",
      "       'fg3_pct_away', 'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away',\n",
      "       'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away',\n",
      "       'pf_away', 'pts_away', 'plus_minus_away', 'video_available_away',\n",
      "       'season_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "relative_filepath = \"NBA_Data\" + os.sep + \"csv\" + os.sep + \"game.csv\"\n",
    "game_df = pd.read_csv(relative_filepath)\n",
    "\n",
    "# Show all column names\n",
    "print(game_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games: 65698\n"
     ]
    }
   ],
   "source": [
    "game_df.head()\n",
    "print(\"Number of games:\" ,len(game_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games without null stats: 46159\n"
     ]
    }
   ],
   "source": [
    "filter_out_null_stats_df = game_df.dropna(subset=['fg3m_home', 'fg3a_home', 'fg3_pct_home', 'fg3m_away', 'fg3a_away', 'fg3_pct_away', 'oreb_home', 'dreb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pf_home', 'pts_home', 'oreb_away', 'dreb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away'])\n",
    "\n",
    "print(\"Number of games without null stats:\",len(filter_out_null_stats_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Seasons with null stats: 225\n",
      "Unique Seasons without null stats: 136\n",
      "Unique Seasons with null stats: [21946 41946 21947 41947 21948 41948 21949 41949 21950 41950 31950 21951\n",
      " 41951 31951 21952 41952 31952 21953 41953 31953 21954 41954 31954 21955\n",
      " 41955 31955 21956 41956 31956 21957 31957 21958 31958 21959 41959 31959\n",
      " 31960 41961 31961 21962 41962 31962 21963 41963 31963 21964 31964 21965\n",
      " 41965 31965 41966 31966 21967 41967 31967 21968 31968 21969 41969 31969\n",
      " 41970 31970 21971 41971 31971 21972 41972 31972 21973 41973 31973 21974\n",
      " 41974 31974 41975 31975 41976 31976 21977 41977 31977 21978 41978 31978\n",
      " 21979 41979 31979 21980 41980 31980 21981 41981 31981 21982 41982 31982\n",
      " 21983 41983 31983 21984 41984 31984 21985 41985 31985 21986 41986 31986\n",
      " 21987 41987 31987 21988 41988 31988 21989 41989 31989 21990 41990 31990\n",
      " 21991 41991 31991 21992 41992 31992 21993 31993 21994 41994 31994 21995\n",
      " 31995 21996 41996 31996 21997 41997 31997 21998 41998 21999 31999 22000\n",
      " 42000 32000 22001 32001 22002 42002 32002 22003 42003 32003 22004 42004\n",
      " 32004 22005 12005 32005 22006 12006 42006 32006 22007 12007 42007 32007\n",
      " 22008 12008 42008 32008 22009 12009 42009 32009 22010 12010 42010 32010\n",
      " 22011 12011 42011 32011 12012 42012 32012 22013 12013 42013 32013 22014\n",
      " 12014 42014 32014 22015 12015 42015 32015 22016 12016 42016 32016 22017\n",
      " 12017 42017 32017 22018 42018 32018 22019 42019 32019 22020 12020 42020\n",
      " 32020 22021 12021 42021 32021 22022 12022 42022 32022]\n",
      "Unique Seasons without null stats: [41979 31979 41980 31980 21981 41981 41982 31982 21983 41983 31983 21984\n",
      " 41984 21985 41985 31985 21986 41986 31986 21987 41987 31987 21988 41988\n",
      " 31988 21989 41989 31989 21990 41990 31990 21991 41991 31991 21992 41992\n",
      " 31992 21993 31993 21994 41994 31994 21995 31995 21996 41996 31996 21997\n",
      " 41997 31997 21998 41998 21999 31999 22000 42000 32000 22001 32001 22002\n",
      " 42002 32002 22003 42003 32003 22004 42004 32004 22005 12005 32005 22006\n",
      " 12006 42006 32006 22007 12007 42007 32007 22008 12008 42008 32008 22009\n",
      " 12009 42009 32009 22010 12010 42010 32010 22011 12011 42011 32011 12012\n",
      " 42012 32012 22013 12013 42013 32013 22014 12014 42014 32014 22015 12015\n",
      " 42015 32015 22016 12016 42016 32016 22017 12017 42017 32017 22018 42018\n",
      " 32018 22019 42019 32019 22020 12020 42020 32020 22021 12021 42021 32021\n",
      " 22022 12022 42022 32022]\n"
     ]
    }
   ],
   "source": [
    "seasons_with_null_stats = game_df['season_id'].unique()\n",
    "seasons_without_null_stats = filter_out_null_stats_df['season_id'].unique()\n",
    "\n",
    "print(f\"Unique Seasons with null stats: {len(seasons_with_null_stats)}\")\n",
    "print(f\"Unique Seasons without null stats: {len(seasons_without_null_stats)}\")\n",
    "\n",
    "print(f\"Unique Seasons with null stats: {seasons_with_null_stats}\")\n",
    "print(f\"Unique Seasons without null stats: {seasons_without_null_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            game_date            \n",
      "                  min         max\n",
      "season_id                        \n",
      "12005      2005-10-10  2005-10-28\n",
      "12006      2006-10-05  2006-10-27\n",
      "12007      2007-10-06  2007-10-25\n",
      "12008      2008-10-05  2008-10-24\n",
      "12009      2009-10-01  2009-10-23\n",
      "...               ...         ...\n",
      "42018      2019-04-13  2019-06-13\n",
      "42019      2020-08-17  2020-10-11\n",
      "42020      2021-05-22  2021-07-20\n",
      "42021      2022-04-16  2022-06-16\n",
      "42022      2023-04-15  2023-06-12\n",
      "\n",
      "[136 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\4168989686.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_out_null_stats_df['game_date'] = pd.to_datetime(filter_out_null_stats_df['game_date'])\n",
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\4168989686.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_out_null_stats_df['game_date'] = filter_out_null_stats_df['game_date'].dt.date\n"
     ]
    }
   ],
   "source": [
    "# Show the seasons and their min date and max date for non-null stats\n",
    "filter_out_null_stats_df['game_date'] = pd.to_datetime(filter_out_null_stats_df['game_date'])\n",
    "filter_out_null_stats_df['game_date'] = filter_out_null_stats_df['game_date'].dt.date\n",
    "\n",
    "filter_out_null_stats_df['game_date'].describe()\n",
    "\n",
    "game_date_seasonid = filter_out_null_stats_df.groupby(['season_id']).agg({'game_date': ['min', 'max']})\n",
    "print(game_date_seasonid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "game_date  min    datetime64[ns]\n",
      "           max    datetime64[ns]\n",
      "dtype: object\n",
      "   season_id  game_date           \n",
      "                    min        max\n",
      "0      12005 2005-10-10 2005-10-28\n",
      "1      12006 2006-10-05 2006-10-27\n",
      "2      12007 2007-10-06 2007-10-25\n",
      "3      12008 2008-10-05 2008-10-24\n",
      "4      12009 2009-10-01 2009-10-23\n",
      "5      12010 2010-10-03 2010-10-22\n",
      "6      12012 2012-10-05 2012-10-26\n",
      "7      12013 2013-10-05 2013-10-25\n",
      "8      12014 2014-10-04 2014-10-24\n",
      "9      12015 2015-10-02 2015-10-23\n",
      "10     12016 2016-10-01 2016-10-21\n",
      "11     12021 2021-10-03 2021-10-15\n"
     ]
    }
   ],
   "source": [
    "# Show seasonid that have october in date (we will not work with preseason data)\n",
    "\n",
    "print(type(game_date_seasonid))\n",
    "game_date_seasonid[('game_date', 'min')] = pd.to_datetime(game_date_seasonid[('game_date', 'min')])\n",
    "game_date_seasonid[('game_date', 'max')] = pd.to_datetime(game_date_seasonid[('game_date', 'max')])\n",
    "\n",
    "print(game_date_seasonid.dtypes)\n",
    "condition1 = game_date_seasonid[('game_date', 'min')].dt.month == 10\n",
    "condition2 = game_date_seasonid[('game_date', 'max')].dt.month == 10\n",
    "october_seasons = game_date_seasonid.loc[condition1 & condition2]\n",
    "october_seasons = october_seasons.reset_index()\n",
    "print(october_seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove preseason data from filtered df\n",
    "\n",
    "filtered_no_preseason_df = filter_out_null_stats_df[~filter_out_null_stats_df['season_id'].isin(october_seasons['season_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Playoffs' 'All-Star' 'All Star' 'Regular Season' 'Pre Season']\n",
      "5\n",
      "After filtering...\n",
      "['Playoffs' 'Regular Season']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Now let us find season type to see what we have to remove\n",
    "\n",
    "season_types = filtered_no_preseason_df['season_type'].unique()\n",
    "print(season_types)\n",
    "print(len(season_types))\n",
    "\n",
    "filtered_df = filtered_no_preseason_df.loc[~( (filtered_no_preseason_df['season_type'] == 'Pre Season') | (filtered_no_preseason_df['season_type'] == 'All Star') | (filtered_no_preseason_df['season_type'] == 'All-Star'))]\n",
    "\n",
    "print(\"After filtering...\")\n",
    "season_types = filtered_df['season_type'].unique()\n",
    "print(season_types)\n",
    "print(len(season_types))\n",
    "\n",
    "filtered_df = filtered_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'season_id', 'team_id_home', 'team_abbreviation_home',\n",
      "       'team_name_home', 'game_id', 'game_date', 'matchup_home', 'wl_home',\n",
      "       'min', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home',\n",
      "       'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home',\n",
      "       'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home',\n",
      "       'pf_home', 'pts_home', 'plus_minus_home', 'video_available_home',\n",
      "       'team_id_away', 'team_abbreviation_away', 'team_name_away',\n",
      "       'matchup_away', 'wl_away', 'fgm_away', 'fga_away', 'fg_pct_away',\n",
      "       'fg3m_away', 'fg3a_away', 'fg3_pct_away', 'ftm_away', 'fta_away',\n",
      "       'ft_pct_away', 'oreb_away', 'dreb_away', 'reb_away', 'ast_away',\n",
      "       'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away',\n",
      "       'plus_minus_away', 'video_available_away', 'season_type'],\n",
      "      dtype='object')\n",
      "['Playoffs' 'Regular Season']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df.columns)\n",
    "print(filtered_df['season_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1610612737: 'ATL', 1610612738: 'BOS', 1610612739: 'CLE', 1610612740: 'NOP', 1610612741: 'CHI', 1610612742: 'DAL', 1610612743: 'DEN', 1610612744: 'GSW', 1610612745: 'HOU', 1610612746: 'LAC', 1610612747: 'LAL', 1610612748: 'MIA', 1610612749: 'MIL', 1610612750: 'MIN', 1610612751: 'BKN', 1610612752: 'NYK', 1610612753: 'ORL', 1610612754: 'IND', 1610612755: 'PHI', 1610612756: 'PHX', 1610612757: 'POR', 1610612758: 'SAC', 1610612759: 'SAS', 1610612760: 'OKC', 1610612761: 'TOR', 1610612762: 'UTA', 1610612763: 'MEM', 1610612764: 'WAS', 1610612765: 'DET', 1610612766: 'CHA'}\n",
      "{1610612737: 0, 1610612738: 1, 1610612739: 2, 1610612740: 3, 1610612741: 4, 1610612742: 5, 1610612743: 6, 1610612744: 7, 1610612745: 8, 1610612746: 9, 1610612747: 10, 1610612748: 11, 1610612749: 12, 1610612750: 13, 1610612751: 14, 1610612752: 15, 1610612753: 16, 1610612754: 17, 1610612755: 18, 1610612756: 19, 1610612757: 20, 1610612758: 21, 1610612759: 22, 1610612760: 23, 1610612761: 24, 1610612762: 25, 1610612763: 26, 1610612764: 27, 1610612765: 28, 1610612766: 29}\n"
     ]
    }
   ],
   "source": [
    "## Convert old team abbreviations to new\n",
    "name_abbreviation = filtered_df.groupby(['team_name_home', 'team_abbreviation_home']).agg({'game_id': 'count'}).reset_index()\n",
    "id_abbreviation = filtered_df.groupby(['team_id_home', 'team_abbreviation_home']).agg({'game_id': 'count'}).reset_index()\n",
    "id_abbreviation_away = filtered_df.groupby(['team_id_away', 'team_abbreviation_away']).agg({'game_id': 'count'}).reset_index()\n",
    "\n",
    "abbreviation_correction_mapping_dict = {\n",
    "    'CHH' : 'CHA',\n",
    "    'GOS' : 'GSW',\n",
    "    'NJN' : 'BKN',\n",
    "    'NOH' : 'NOP',\n",
    "    'NOK' : 'NOP',\n",
    "    'PHL' : 'PHI',\n",
    "    'SEA' : 'OKC',\n",
    "    'SAN' : 'SAS',\n",
    "    'UTH' : 'UTA',\n",
    "    'VAN' : 'MEM'\n",
    "}\n",
    "\n",
    "id_abbreviation['team_abbreviation_home'] = id_abbreviation['team_abbreviation_home'].replace(abbreviation_correction_mapping_dict)\n",
    "id_abbreviation = id_abbreviation.groupby(['team_id_home', 'team_abbreviation_home']).sum('game_id').reset_index()\n",
    "\n",
    "id_abbreviation_away['team_abbreviation_away'] = id_abbreviation_away['team_abbreviation_away'].replace(abbreviation_correction_mapping_dict)\n",
    "id_abbreviation_away = id_abbreviation_away.groupby(['team_id_away', 'team_abbreviation_away']).sum('game_id').reset_index()\n",
    "\n",
    "# print(id_abbreviation)\n",
    "# print(id_abbreviation_away)\n",
    "\n",
    "teamID_abbreviation_df = id_abbreviation.drop('game_id', axis=1)\n",
    "teamID_abbreviation_df = teamID_abbreviation_df.set_index('team_id_home')\n",
    "teamID_abbreviation_dict = teamID_abbreviation_df.to_dict(orient='index')\n",
    "teamID_abbreviation_dict = { k: v['team_abbreviation_home'] for k, v in teamID_abbreviation_dict.items() }\n",
    "teamID_newID_dict = { real_team_id : new_team_id  for new_team_id, (real_team_id, team_abbrev) in enumerate(teamID_abbreviation_dict.items()) }\n",
    "\n",
    "print(teamID_abbreviation_dict)\n",
    "print(teamID_newID_dict)\n",
    "\n",
    "teamID_mappings = {'teamID_abbreviation_dict' : teamID_abbreviation_dict, 'teamID_newID_dict': teamID_newID_dict}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us calculate the rest days ##\n",
    "\n",
    "# First we will order the games by game date, and change all season_id to season year\n",
    "filtered_df['game_date'] = pd.to_datetime(filtered_df['game_date'])\n",
    "filtered_df = filtered_df.sort_values(by='game_date').reset_index(drop=True)\n",
    "\n",
    "# Just get season id, game date, and season type dataframe\n",
    "ordered_season_df = filtered_df['season_id'].drop_duplicates().to_frame().reset_index(drop=True)\n",
    "\n",
    "# Remove first digit from season id, so that all season id just becomes the year of which the season is played\n",
    "ordered_season_df['new_season_id'] = ordered_season_df['season_id'].astype(str).str[1:].astype(int)\n",
    "ordered_season_dict = dict(zip(ordered_season_df['season_id'], ordered_season_df['new_season_id']))\n",
    "filtered_df['new_season_id'] = filtered_df['season_id'].replace(ordered_season_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\3517732948.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  game_hometeams_df.rename(columns ={'team_id_home' :'team_id'}, inplace=True)\n",
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\3517732948.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  game_hometeams_df.loc[:,'team_status'] = 'home'\n",
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\3517732948.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  game_awayteams_df.rename(columns ={'team_id_away' :'team_id'}, inplace=True)\n",
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\3517732948.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  game_awayteams_df.loc[:, 'team_status'] = 'away'\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with just team, game date,home/away status, season_id\n",
    "game_hometeams_df = filtered_df[['new_season_id', 'game_date' , 'team_id_home' ]]\n",
    "game_hometeams_df.rename(columns ={'team_id_home' :'team_id'}, inplace=True)\n",
    "game_hometeams_df.loc[:,'team_status'] = 'home'\n",
    "\n",
    "game_awayteams_df = filtered_df[['new_season_id', 'game_date' , 'team_id_away' ]]\n",
    "game_awayteams_df.rename(columns ={'team_id_away' :'team_id'}, inplace=True)\n",
    "game_awayteams_df.loc[:, 'team_status'] = 'away'\n",
    "\n",
    "games_df = pd.concat([game_hometeams_df, game_awayteams_df]).reset_index(drop=True)\n",
    "games_df.sort_values(by=['team_id', 'new_season_id',  'game_date'], inplace=True, ignore_index=True)\n",
    "games_df['previous_game_date'] = games_df.groupby(by=['team_id', 'new_season_id'])[['game_date']].shift(1)\n",
    "\n",
    "games_df['rest_days'] = (games_df.loc[:,'game_date'] - games_df.loc[:,'previous_game_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_games_df = games_df.loc[games_df['team_status'] == 'home'].reset_index(drop=True)\n",
    "away_games_df = games_df.loc[games_df['team_status'] == 'away'].reset_index(drop=True)\n",
    "\n",
    "home_games_df.rename(columns={'rest_days' : 'rest_days_home'}, inplace=True)\n",
    "away_games_df.rename(columns={'rest_days' : 'rest_days_away'}, inplace=True)\n",
    "home_games_df.rename(columns={'team_id' : 'team_id_home'}, inplace=True)\n",
    "away_games_df.rename(columns={'team_id' : 'team_id_away'}, inplace=True)\n",
    "\n",
    "home_games_df = home_games_df.drop(columns=['team_status', 'previous_game_date'])\n",
    "away_games_df = away_games_df.drop(columns=['team_status', 'previous_game_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "filtered_df = filtered_df.merge(right=home_games_df, how='left', left_on=['new_season_id', 'game_date', 'team_id_home'], right_on=['new_season_id', 'game_date', 'team_id_home'])\n",
    "filtered_df = filtered_df.merge(right=away_games_df, how='left' , left_on=['new_season_id', 'game_date', 'team_id_away'], right_on=['new_season_id', 'game_date', 'team_id_away'])\n",
    "\n",
    "filtered_df[['rest_days_home', 'rest_days_away']] = filtered_df[['rest_days_home', 'rest_days_away']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season_id', 'team_id_home', 'game_date', 'wl_home', 'fga_home',\n",
      "       'fg_pct_home', 'fg3a_home', 'oreb_home', 'dreb_home', 'ast_home',\n",
      "       'stl_home', 'blk_home', 'tov_home', 'pf_home', 'team_id_away',\n",
      "       'fga_away', 'fg3a_away', 'oreb_away', 'dreb_away', 'ast_away',\n",
      "       'stl_away', 'blk_away', 'tov_away', 'pf_away', 'season_type',\n",
      "       'new_season_id', 'rest_days_home', 'rest_days_away'],\n",
      "      dtype='object')\n",
      "       season_id  team_id_home  game_date  wl_home  fga_home  fg_pct_home  \\\n",
      "0          41979    1610612747 1980-05-07        0      95.0        0.505   \n",
      "1          41979    1610612755 1980-05-10        0      93.0        0.484   \n",
      "2          41979    1610612755 1980-05-16        0      89.0        0.528   \n",
      "3          41980    1610612738 1981-05-05        1      95.0        0.432   \n",
      "4          41980    1610612738 1981-05-07        0      82.0        0.500   \n",
      "...          ...           ...        ...      ...       ...          ...   \n",
      "44544      42022    1610612743 2023-06-01        1      79.0        0.506   \n",
      "44545      42022    1610612743 2023-06-04        0      75.0        0.520   \n",
      "44546      42022    1610612748 2023-06-07        0      92.0        0.370   \n",
      "44547      42022    1610612748 2023-06-09        0      78.0        0.449   \n",
      "44548      42022    1610612743 2023-06-12        1      84.0        0.452   \n",
      "\n",
      "       fg3a_home  oreb_home  dreb_home  ast_home  stl_home  blk_home  \\\n",
      "0            1.0       15.0       37.0      32.0      12.0       7.0   \n",
      "1            4.0       13.0       24.0      34.0      12.0       8.0   \n",
      "2            6.0        7.0       29.0      27.0       4.0      11.0   \n",
      "3            1.0       25.0       29.0      23.0       6.0       5.0   \n",
      "4            3.0       14.0       34.0      17.0       6.0       7.0   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "44544       27.0        6.0       39.0      29.0       4.0       4.0   \n",
      "44545       28.0        9.0       29.0      23.0       7.0       2.0   \n",
      "44546       35.0       10.0       23.0      20.0       7.0       3.0   \n",
      "44547       25.0        8.0       29.0      23.0       2.0       3.0   \n",
      "44548       28.0       11.0       46.0      21.0       6.0       7.0   \n",
      "\n",
      "       tov_home  pf_home  team_id_away  fga_away  fg3a_away  oreb_away  \\\n",
      "0          26.0     27.0    1610612755      85.0        1.0        5.0   \n",
      "1          13.0     25.0    1610612747      92.0        1.0       22.0   \n",
      "2          18.0     27.0    1610612747      92.0        2.0       17.0   \n",
      "3          19.0     21.0    1610612745      99.0        2.0       19.0   \n",
      "4          22.0     27.0    1610612745      85.0        2.0       13.0   \n",
      "...         ...      ...           ...       ...        ...        ...   \n",
      "44544      10.0      8.0    1610612748      96.0       39.0       11.0   \n",
      "44545      14.0     21.0    1610612748      78.0       35.0        8.0   \n",
      "44546       4.0     22.0    1610612743      80.0       18.0       13.0   \n",
      "44547      15.0     19.0    1610612743      79.0       28.0        5.0   \n",
      "44548      15.0     13.0    1610612748      96.0       35.0       11.0   \n",
      "\n",
      "       dreb_away  ast_away  stl_away  blk_away  tov_away  pf_away  \\\n",
      "0           29.0      34.0      14.0      11.0      20.0     21.0   \n",
      "1           34.0      20.0       5.0       5.0      20.0     25.0   \n",
      "2           35.0      27.0      14.0       4.0      17.0     22.0   \n",
      "3           23.0      23.0      15.0       3.0      10.0     20.0   \n",
      "4           22.0      16.0       6.0       8.0       9.0     17.0   \n",
      "...          ...       ...       ...       ...       ...      ...   \n",
      "44544       32.0      26.0       5.0       4.0       8.0     15.0   \n",
      "44545       23.0      28.0       5.0       4.0      11.0     22.0   \n",
      "44546       45.0      28.0       3.0       5.0      14.0     18.0   \n",
      "44547       29.0      26.0      11.0       7.0       8.0     18.0   \n",
      "44548       33.0      18.0       9.0       7.0       8.0     21.0   \n",
      "\n",
      "       season_type  new_season_id  rest_days_home  rest_days_away  \n",
      "0                1           1979             0.0             0.0  \n",
      "1                1           1979             3.0             3.0  \n",
      "2                1           1979             6.0             6.0  \n",
      "3                1           1980             0.0             0.0  \n",
      "4                1           1980             2.0             2.0  \n",
      "...            ...            ...             ...             ...  \n",
      "44544            1           2022            10.0             3.0  \n",
      "44545            1           2022             3.0             3.0  \n",
      "44546            1           2022             3.0             3.0  \n",
      "44547            1           2022             2.0             2.0  \n",
      "44548            1           2022             3.0             3.0  \n",
      "\n",
      "[44549 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\736446779.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df['wl_home'] = final_df['wl_home'].replace({'W': 1, 'L': 0})\n",
      "C:\\Users\\Alex1\\AppData\\Local\\Temp\\ipykernel_25172\\736446779.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df['season_type'] = final_df['season_type'].replace({'Regular Season': 0, 'Playoffs': 1})\n"
     ]
    }
   ],
   "source": [
    "final_df = filtered_df.drop(['index', 'team_abbreviation_home', 'team_name_home',\n",
    "       'game_id', 'matchup_home', 'min', 'fgm_home', 'fg3m_home', 'fg3_pct_home',\n",
    "       'ftm_home', 'fta_home', 'ft_pct_home', 'reb_home',\n",
    "       'pts_home', 'plus_minus_home', 'video_available_home',\n",
    "       'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away',\n",
    "       'fgm_away', 'fg_pct_away', 'fg3m_away',\n",
    "       'fg3_pct_away', 'ftm_away', 'fta_away', 'ft_pct_away',\n",
    "       'reb_away', 'pts_away', 'plus_minus_away', 'video_available_away'], axis=1)\n",
    "\n",
    "print(final_df.columns)\n",
    "\n",
    "final_df['wl_home'] = final_df['wl_home'].replace({'W': 1, 'L': 0})\n",
    "final_df['season_type'] = final_df['season_type'].replace({'Regular Season': 0, 'Playoffs': 1})\n",
    "\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season_id         0\n",
      "team_id_home      0\n",
      "game_date         0\n",
      "wl_home           0\n",
      "fga_home          0\n",
      "fg_pct_home       0\n",
      "fg3a_home         0\n",
      "oreb_home         0\n",
      "dreb_home         0\n",
      "ast_home          0\n",
      "stl_home          0\n",
      "blk_home          0\n",
      "tov_home          0\n",
      "pf_home           0\n",
      "team_id_away      0\n",
      "fga_away          0\n",
      "fg3a_away         0\n",
      "oreb_away         0\n",
      "dreb_away         0\n",
      "ast_away          0\n",
      "stl_away          0\n",
      "blk_away          0\n",
      "tov_away          0\n",
      "pf_away           0\n",
      "season_type       0\n",
      "new_season_id     0\n",
      "rest_days_home    0\n",
      "rest_days_away    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dictionary to a pickle files\n",
    "\n",
    "with open('teamID_mappings.pickle', 'wb') as file:\n",
    "    pickle.dump(teamID_mappings, file)\n",
    "\n",
    "with open('seasonID_to_NewSeasonID_mappings.pickle', 'wb') as file:\n",
    "    pickle.dump(ordered_season_dict ,file)\n",
    "\n",
    "with open('NBA_Data_Cleaned_df.pickle', 'wb') as file:\n",
    "    pickle.dump(final_df, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
